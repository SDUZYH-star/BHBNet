{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8d893e-48ad-4fa6-9130-93676e223278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from d2l import torch as d2l\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc,precision_recall_curve\n",
    "import seaborn as sns\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ff16b6-b208-41b3-b806-06cb49e4a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 50      # Number of training epochs\n",
    "batch_size = 128     # Batch size\n",
    "learning_rate = 0.0001 # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a59d4228-83a0-4352-8577-f8c69fa696bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Attention Module\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel attention module with region-based feature extraction.\n",
    "    \n",
    "    Args:\n",
    "        in_planes (int): Number of input channels\n",
    "        num_regions (int): Number of regions to split feature map (default: 4)\n",
    "        pool_type (str): Pooling type - 'avg' or 'max' (default: 'avg')\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, num_regions=4, pool_type='avg'):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        \n",
    "        self.in_planes = in_planes\n",
    "        self.num_regions = num_regions\n",
    "        self.pool_type = pool_type\n",
    "        \n",
    "        # Region configuration (square regions)\n",
    "        self.num_region_rows = num_regions\n",
    "        self.num_region_cols = num_regions\n",
    "        \n",
    "        # Pooling layer selection\n",
    "        if pool_type == 'avg':\n",
    "            self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        elif pool_type == 'max':\n",
    "            self.pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid pool_type. Choose 'avg' or 'max'.\")\n",
    "        \n",
    "        # 1D convolutions for each region\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv1d(1, 1, 1, bias=False)\n",
    "            for _ in range(num_regions * num_regions)\n",
    "        ])\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        \n",
    "        # Calculate region dimensions\n",
    "        region_height = h // self.num_region_rows\n",
    "        region_width = w // self.num_region_cols\n",
    "        \n",
    "        # Extract and pool features from each region\n",
    "        pooled_features = []\n",
    "        for i in range(self.num_region_rows):\n",
    "            for j in range(self.num_region_cols):\n",
    "                x_crop = x[:, :, \n",
    "                          i*region_height:(i+1)*region_height, \n",
    "                          j*region_width:(j+1)*region_width]\n",
    "                pooled = self.pool(x_crop)\n",
    "                pooled_features.append(pooled.squeeze(-1).permute(0,2,1))  \n",
    "        \n",
    "        # Process each pooled feature\n",
    "        processed_features = []\n",
    "        for i, pooled in enumerate(pooled_features):\n",
    "            conv_out = self.conv1d_list[i](pooled)\n",
    "            processed_features.append(conv_out)\n",
    "            \n",
    "        # Combine features through summation\n",
    "        processed_features = torch.sum(torch.stack(processed_features, dim=0), dim=0)\n",
    "        \n",
    "        # Compute channel attention weights\n",
    "        attention_weights = self.sigmoid(processed_features)  \n",
    "        \n",
    "        # Reshape to original feature map dimensions\n",
    "        attention_weights = attention_weights.permute(0,2,1).unsqueeze(-1)\n",
    "        \n",
    "        return attention_weights\n",
    "\n",
    "\n",
    "# Spatial Attention Module  \n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial attention module with grouped feature processing.\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): Number of input channels\n",
    "        groups (int): Number of channel groups (default: 4)\n",
    "        kernel_size (int): Convolution kernel size (3 or 7, default: 7)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, groups=4, kernel_size=7):  \n",
    "        super(SpatialAttention, self).__init__()  \n",
    "  \n",
    "        self.groups = groups\n",
    "        self.channels_per_group = in_channels // groups  \n",
    "\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        \n",
    "        # Convolution layers for each group\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv2d(1, 1, kernel_size, padding=padding, bias=False)\n",
    "            for _ in range(groups)\n",
    "        ])\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        # Process each channel group\n",
    "        pooled_features = [] \n",
    "        for i in range(self.groups):  \n",
    "            # Extract channel group\n",
    "            x_crop = x[:, i*self.channels_per_group:(i+1)*self.channels_per_group, :, :]  \n",
    "            # Channel-wise average pooling\n",
    "            pooled = torch.mean(x_crop, dim=1, keepdim=True)  \n",
    "            pooled_features.append(pooled)  \n",
    "            \n",
    "        processed_features = []\n",
    "        for i, pooled in enumerate(pooled_features):\n",
    "            conv_out = self.conv1d_list[i](pooled)\n",
    "            processed_features.append(conv_out)\n",
    "            \n",
    "        # Combine features through summation\n",
    "        processed_features = torch.sum(torch.stack(processed_features, dim=0), dim=0)\n",
    "  \n",
    "        # Compute spatial attention weights\n",
    "        attention_weights = self.sigmoid(processed_features)  \n",
    "  \n",
    "        return attention_weights\n",
    "\n",
    "\n",
    "# Convolutional Block Attention Module (CBAM)\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"CBAM attention module combining channel and spatial attention.\n",
    "    \n",
    "    Args:\n",
    "        in_planes (int): Number of input channels\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes)  # Channel attention\n",
    "        self.sa = SpatialAttention(in_planes)  # Spatial attention\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply channel attention\n",
    "        out = x * self.ca(x)\n",
    "        # Apply spatial attention\n",
    "        result = out * self.sa(out)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c641c49-83f8-42f2-9bb2-708d15a5e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHAB(nn.Module):  #@save\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=True, strides=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1,stride=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "        self.CBAM = CBAM(num_channels)\n",
    "        self.gelu = nn.GELU()\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.gelu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        Y = self.CBAM(Y)\n",
    "        Y += X\n",
    "        \n",
    "        return self.gelu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b01a606-dbc9-4b58-bfcf-ca7ea84d46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BHBNet(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(BHBNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        self.b1 = RHAB(64,128)\n",
    "        self.b2 = RHAB(128,256)\n",
    "        self.b3 = RHAB(256,512)\n",
    "        self.gru = nn.GRU(64,128,3)\n",
    "        self.gelu = nn.GELU()  \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128,64)\n",
    "        self.fc2 = nn.Linear(64,6)\n",
    "\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        x = x.view(x.size(0),1,64,64)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.gelu(x)\n",
    "        # RHAM\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = x.view(x.size(0), 512, -1)\n",
    "        # GRU module  \n",
    "        x, _ = self.gru(x)    \n",
    "        x = x[:, -1, :]  \n",
    "        # output module\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7d3721-d685-4b95-bcb0-cf7230f14dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read spectral data CSV files and add label column\n",
    "try:\n",
    "    # Load spectral data for each class\n",
    "    BHB_spec_df = pd.read_csv(r\"D:\\ZYH\\data\\BHB\\LAMOST_BHB_spectra.csv\")\n",
    "    Hsd_spec_df = pd.read_csv(r\"D:\\ZYH\\data\\Hsd\\LAMOST_Hsd_spectra.csv\")\n",
    "    A_spec_df = pd.read_csv(r\"D:\\ZYH\\data\\A\\LAMOST_A_spectra.csv\")\n",
    "    B_spec_df = pd.read_csv(r\"D:\\ZYH\\data\\B\\LAMOST_B_spectra.csv\")\n",
    "    \n",
    "   \n",
    "    BHB_spec_df['label'] = 1\n",
    "    Hsd_spec_df['label'] = 0\n",
    "    A_spec_df['label'] = 0\n",
    "    B_spec_df['label'] = 0\n",
    "    \n",
    "    # Combine all datasets including label column\n",
    "    All_spec_df = pd.concat([BHB_spec_df, Hsd_spec_df, A_spec_df, B_spec_df], ignore_index=True)\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found - {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29704cf3-8e32-4aea-945c-199056919d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "   torch.manual_seed(seed)\n",
    "   torch.cuda.manual_seed_all(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "   torch.backends.cudnn.deterministic = True\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff65346-89e8-4299-b089-c3e1a4630ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for reading spectral data, returns data and labels\n",
    "class SpectraDataset(Dataset):\n",
    "    def __init__(self, specdata):\n",
    "        # Ensure all columns except the label column are numeric\n",
    "        self.specdata = specdata\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Convert data row to torch tensor\n",
    "        specdata = torch.tensor(self.specdata.iloc[index, :-1].values, dtype=torch.float32)\n",
    "        # Get label\n",
    "        label = self.specdata.iloc[index, -1]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        return specdata, label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return number of samples in dataset\n",
    "        return len(self.specdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f1781b-75a0-4b74-baa7-1db3bf724605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instance\n",
    "Spectra_dataset = SpectraDataset(All_spec_df)\n",
    "\n",
    "# Split into training, validation and test sets\n",
    "train_dataset, valid_test_dataset = train_test_split(Spectra_dataset, test_size=0.2, random_state=42)  \n",
    "valid_dataset, test_dataset = train_test_split(train_valid_dataset, test_size=0.5, random_state=42)    \n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2dadd-2be4-40eb-a23c-bb4eeefc0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version: \", torchvision.__version__)\n",
    "\n",
    "# Device configuration - Check if CUDA acceleration is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9f7fb4-191b-4b50-bb5e-887a5a3d29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = BHBNet()\n",
    "model.load_state_dict(torch.load(r\"D:\\ZYH\\代码\\六分类\\单模态_光谱分类模型\\save_model\\best_six_class.pth\"))\n",
    "model.fc2 = nn.Linear(64, 2)\n",
    "for name, param in model.named_parameters():  \n",
    "    if 'fc2' not in name:  \n",
    "        param.requires_grad = False\n",
    "# print(model)\n",
    "model.to(device)\n",
    "\n",
    "# Set up loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate,weight_decay=5e-2)\n",
    "\n",
    "# Define polynomial decay function\n",
    "def poly_decay(epoch, total_epochs=100, power=1):\n",
    "    return (1 - epoch / total_epochs) ** power\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: poly_decay(epoch, num_epochs, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a85366-b167-46a3-a99b-19f30d876421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_accuracy_gpu(net, data_iter, loss, device=None): #@save\n",
    "    \"\"\"Compute the model's accuracy on a dataset using GPU.\"\"\"\n",
    "    net.eval()  # Set to evaluation mode\n",
    "    for module in net.modules():\n",
    "        if module.__class__.__name__.startswith(\"Dropout\"):\n",
    "            module.train()\n",
    "    if not device:\n",
    "        device = next(iter(net.parameters())).device\n",
    "    fwd_passes = 50\n",
    "    # Number of correct predictions, total predictions\n",
    "    metric = d2l.Accumulator(3)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # Required for BERT fine-tuning (to be discussed later)\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            predictions = []\n",
    "            for fwd_pass in range(fwd_passes):\n",
    "                output = net(X)\n",
    "                predictions.append(output)\n",
    "            predictions = torch.stack(predictions, dim=0)\n",
    "            l = loss(torch.mean(predictions, dim=0), y.long())\n",
    "            y = y.cpu()\n",
    "            predictions = F.softmax(predictions, dim=2)\n",
    "            y_pred = torch.mean(predictions, dim=0)\n",
    "            y_hat = y_pred.argmax(axis=1).long()    \n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "            y_hat = y_hat.cpu()\n",
    "            cmp = y_hat.type(y.dtype) == y\n",
    "            metric.add(l * X.shape[0], float(cmp.type(y.dtype).sum()), X.shape[0])\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def evaluate_accuracy_gpu_test(net, data_iter, loss, device=None): #@save\n",
    "    \"\"\"Compute the model's accuracy on a dataset using GPU.\"\"\"\n",
    "    net.eval()  # Set to evaluation mode\n",
    "    for module in net.modules():\n",
    "        if module.__class__.__name__.startswith(\"Dropout\"):\n",
    "            module.train()\n",
    "    if not device:\n",
    "        device = next(iter(net.parameters())).device\n",
    "    # Number of correct predictions, total predictions\n",
    "    metric = d2l.Accumulator(3)\n",
    "    confusion_mat = torch.zeros(6, 6, dtype=torch.int64, device=\"cpu\")\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    y_0_preds = []\n",
    "    fwd_passes = 50\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # Required for BERT fine-tuning (to be discussed later)\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            predictions = []\n",
    "            for fwd_pass in range(fwd_passes):\n",
    "                output = net(X)\n",
    "                predictions.append(output)\n",
    "            predictions = torch.stack(predictions, dim=0)\n",
    "            y = y.to(device)\n",
    "            l = loss(torch.mean(predictions, dim=0), y.long())\n",
    "            y = y.cpu()\n",
    "            predictions = F.softmax(predictions, dim=2)\n",
    "            y_pred = torch.mean(predictions, dim=0)\n",
    "            y_hat = y_pred.argmax(axis=1).long()\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "            y_hat = y_hat.cpu()\n",
    "            cmp = y_hat.type(y.dtype) == y\n",
    "            metric.add(l * X.shape[0], float(cmp.type(y.dtype).sum()), X.shape[0])\n",
    "            y_trues.extend(y)\n",
    "            y_preds.extend(y_pred)\n",
    "            y_0_preds.extend(y_pred[:, 1])\n",
    "            # Update confusion matrix\n",
    "            for i in range(len(y)):  \n",
    "                confusion_mat[y[i].long(), y_hat[i].long()] += 1\n",
    "    test_l = metric[0] / metric[1]            \n",
    "    accuracy = metric[1] / metric[2]\n",
    "    precision, recall, f1_score = calculate_metrics(confusion_mat, 2)\n",
    "    \n",
    "    class_names = [\"Hsd/A/B\",\"BHB\"]\n",
    "\n",
    "    # Create a figure with two subplots  \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 columns  \n",
    "  \n",
    "    # Precision-Recall curve\n",
    "    precision_list = []    \n",
    "    recall_list = []    \n",
    "    for i, name in enumerate(class_names):  \n",
    "        y_pred = [p[i] for p in y_preds]  \n",
    "        y_true = np.array([int(t == i) for t in y_trues])  # Convert labels to binary form  \n",
    "        p, r, _ = precision_recall_curve(y_true, y_pred)  \n",
    "        precision_list.append(p)    \n",
    "        recall_list.append(r)   \n",
    "        axs[0].plot(r, p, label=f'{name} (area = {auc(r, p):0.2f})')  \n",
    "    axs[0].set_xlabel('Recall', fontsize=14)  \n",
    "    axs[0].set_ylabel('Precision', fontsize=14)  \n",
    "    axs[0].legend(loc=\"lower left\", fontsize=14)\n",
    "    axs[0].tick_params(labelsize=14)\n",
    "  \n",
    "    # Confusion matrix  \n",
    "    sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Purples', ax=axs[1])  \n",
    "    axs[1].set_xlabel('Predicted labels', fontsize=14)  \n",
    "    axs[1].set_ylabel('True labels', fontsize=14)  \n",
    "    axs[1].set_xticks([0.5, 1.5])\n",
    "    axs[1].set_yticks([0.5, 1.5])\n",
    "    axs[1].set_xticklabels(class_names, fontsize=14)\n",
    "    axs[1].set_yticklabels(class_names, fontsize=14, rotation=0)\n",
    "  \n",
    "    plt.tight_layout()  \n",
    "\n",
    "    plt.savefig(r\"D:\\ZYH\\code\\bianry\\figure\\combined_plot.png\", dpi=600, bbox_inches='tight')\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "def calculate_metrics(confusion_mat, num_classes):\n",
    "    precision = torch.zeros(num_classes)\n",
    "    recall = torch.zeros(num_classes)\n",
    "    f1_score = torch.zeros(num_classes)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        tp = confusion_mat[i, i]\n",
    "        fp = torch.sum(confusion_mat[i, :]) - tp\n",
    "        fn = torch.sum(confusion_mat[:, i]) - tp\n",
    "        precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc0406-ca45-4605-9cd8-170614a220af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on the training set and validation on the validation set\n",
    "strattime = datetime.datetime.now()\n",
    "for epoch in range(num_epochs):\n",
    "    metric = d2l.Accumulator(3)\n",
    "    model.train()\n",
    "    for i, (X,y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = model(X)\n",
    "        l= loss(y_hat, y.long())\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "        train_l = metric[0] / metric[2]\n",
    "        train_acc = metric[1] / metric[2]\n",
    "    valid_l, valid_acc = evaluate_accuracy_gpu(model, valid_loader, loss)\n",
    "    scheduler.step()\n",
    "    if epoch == 0:\n",
    "        best_valid_l = valid_l\n",
    "        torch.save(model.state_dict(), r\"D:\\ZYH\\code\\binary\\model\\binary_fc.pth\")\n",
    "    if epoch > 0 and best_valid_l > valid_l: \n",
    "        best_valid_l = valid_l\n",
    "        torch.save(model.state_dict(), r\"D:\\ZYH\\code\\binary\\model\\binary_fc.pth\")\n",
    "    print(train_l,valid_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17873d6c-5b6b-4042-b028-b0ed694bba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalution on the test set\n",
    "model.load_state_dict(torch.load(r\"D:\\ZYH\\codebinary\\save_model\\binary_fc_best.pth\"))\n",
    "test_acc, test_pre, test_rec, test_f1 = evaluate_accuracy_gpu_test(model,test_loader, loss)\n",
    "for i in range(2):\n",
    "    print(f'Precision {test_pre[i]:.4f}, Recall {test_rec[i]:.4f}, F_1 score {test_f1[i]:.4f}')\n",
    "print(f'Total Accuracy {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014bf27-db66-43f7-b91b-4cf6cd1dc126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
